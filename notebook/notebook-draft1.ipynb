{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA Microarray Machine Learning\n",
    "\n",
    "- Data source is from UCI Machine Learning Repo [https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq]\n",
    "- The dataset is a collection gene expressions of patients having different types of tumor: BRCA(breast), KIRC(kidney), COAD(colon), LUAD(lung) and PRAD(prostate).\n",
    "\n",
    "\n",
    "## Import Data and Exploration\n",
    "The dataset contains 801 instances and 20531 features. It is a high dimensional low sample size dataset with multiple classes. The first step of the project is importing the dataset and perform some explorations of the dataset to gain some basic understanding. In terms of visualizations, it is difficult to visualize because of high dimensions. t -Distributed Stochastic Neighbor Embedding or t-SNE is a technique that I used to perform dimension reduction to visualize the data in 2D.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0  gene_0    gene_1    gene_2    gene_3     gene_4  gene_5  \\\n",
      "0   sample_0     0.0  2.017209  3.265527  5.478487  10.431999     0.0   \n",
      "1   sample_1     0.0  0.592732  1.588421  7.586157   9.623011     0.0   \n",
      "2   sample_2     0.0  3.511759  4.327199  6.881787   9.870730     0.0   \n",
      "3   sample_3     0.0  3.663618  4.507649  6.659068  10.196184     0.0   \n",
      "4   sample_4     0.0  2.655741  2.821547  6.539454   9.738265     0.0   \n",
      "\n",
      "     gene_6    gene_7  gene_8     ...      gene_20521  gene_20522  gene_20523  \\\n",
      "0  7.175175  0.591871     0.0     ...        4.926711    8.210257    9.723516   \n",
      "1  6.816049  0.000000     0.0     ...        4.593372    7.323865    9.740931   \n",
      "2  6.972130  0.452595     0.0     ...        5.125213    8.127123   10.908640   \n",
      "3  7.843375  0.434882     0.0     ...        6.076566    8.792959   10.141520   \n",
      "4  6.566967  0.360982     0.0     ...        5.996032    8.891425   10.373790   \n",
      "\n",
      "   gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
      "0    7.220030    9.119813   12.003135    9.650743    8.921326    5.286759   \n",
      "1    6.256586    8.381612   12.674552   10.517059    9.397854    2.094168   \n",
      "2    5.401607    9.911597    9.045255    9.788359   10.090470    1.683023   \n",
      "3    8.942805    9.601208   11.392682    9.694814    9.684365    3.292001   \n",
      "4    7.181162    9.846910   11.922439    9.217749    9.461191    5.110372   \n",
      "\n",
      "   gene_20530  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "\n",
      "[5 rows x 20532 columns]\n",
      "Unnamed: 0     object\n",
      "gene_0        float64\n",
      "gene_1        float64\n",
      "gene_2        float64\n",
      "gene_3        float64\n",
      "gene_4        float64\n",
      "gene_5        float64\n",
      "gene_6        float64\n",
      "gene_7        float64\n",
      "gene_8        float64\n",
      "gene_9        float64\n",
      "gene_10       float64\n",
      "gene_11       float64\n",
      "gene_12       float64\n",
      "gene_13       float64\n",
      "gene_14       float64\n",
      "gene_15       float64\n",
      "gene_16       float64\n",
      "gene_17       float64\n",
      "gene_18       float64\n",
      "gene_19       float64\n",
      "gene_20       float64\n",
      "gene_21       float64\n",
      "gene_22       float64\n",
      "gene_23       float64\n",
      "gene_24       float64\n",
      "gene_25       float64\n",
      "gene_26       float64\n",
      "gene_27       float64\n",
      "gene_28       float64\n",
      "               ...   \n",
      "gene_20501    float64\n",
      "gene_20502    float64\n",
      "gene_20503    float64\n",
      "gene_20504    float64\n",
      "gene_20505    float64\n",
      "gene_20506    float64\n",
      "gene_20507    float64\n",
      "gene_20508    float64\n",
      "gene_20509    float64\n",
      "gene_20510    float64\n",
      "gene_20511    float64\n",
      "gene_20512    float64\n",
      "gene_20513    float64\n",
      "gene_20514    float64\n",
      "gene_20515    float64\n",
      "gene_20516    float64\n",
      "gene_20517    float64\n",
      "gene_20518    float64\n",
      "gene_20519    float64\n",
      "gene_20520    float64\n",
      "gene_20521    float64\n",
      "gene_20522    float64\n",
      "gene_20523    float64\n",
      "gene_20524    float64\n",
      "gene_20525    float64\n",
      "gene_20526    float64\n",
      "gene_20527    float64\n",
      "gene_20528    float64\n",
      "gene_20529    float64\n",
      "gene_20530    float64\n",
      "Length: 20532, dtype: object\n",
      "  Unnamed: 0 Class\n",
      "0   sample_0  PRAD\n",
      "1   sample_1  LUAD\n",
      "2   sample_2  PRAD\n",
      "3   sample_3  PRAD\n",
      "4   sample_4  BRCA\n",
      "Unnamed: 0    object\n",
      "Class         object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "The shape of dataset:\n",
      "(801, 20531)\n",
      "(801, 2)\n",
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 801 samples in 0.582s...\n",
      "[t-SNE] Computed neighbors for 801 samples in 23.347s...\n",
      "[t-SNE] Computed conditional probabilities for sample 801 / 801\n",
      "[t-SNE] Mean sigma: 48.192174\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 57.251804\n",
      "[t-SNE] Error after 300 iterations: 0.820377\n",
      "TSNE took at 31.18 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data_path = \"../data/\"\n",
    "# load the dataset\n",
    "X = pd.read_csv(data_path + \"RNA_data/data.csv\")\n",
    "Y = pd.read_csv(data_path + \"RNA_data/labels.csv\")\n",
    "\n",
    "# basic overview of data dimension\n",
    "print(X.head())\n",
    "print(X.dtypes)\n",
    "print(Y.head())\n",
    "print(Y.dtypes)\n",
    "\n",
    "# convert dataframe into a numpy array\n",
    "X = X.dropna()\n",
    "# drop the first column which only contains strings\n",
    "X = X.drop(X.columns[X.columns.str.contains('unnamed', case=False)], axis=1)\n",
    "print(\"\\n\\nThe shape of dataset:\")\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# label encode the multiple class string into integer values\n",
    " # label encode the multiple class string into integer values\n",
    "Y = Y.drop(Y.columns[0], axis=1)\n",
    "Y = Y.apply(LabelEncoder().fit_transform)\n",
    "Y_data = Y.values.flatten()\n",
    "\n",
    "# use TSNE to visualize the high dimension data in 2D\n",
    "t0 = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300, random_state=100)\n",
    "tsne_results = tsne.fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"TSNE took at %.2f seconds\" % (t1 - t0))\n",
    "\n",
    "# visualize TSNE\n",
    "x_axis = tsne_results[:,0]\n",
    "y_axis = tsne_results[:,1]\n",
    "plt.scatter(x_axis, y_axis, c=Y_data, cmap=plt.cm.get_cmap(\"jet\", 100))\n",
    "plt.colorbar(ticks=range(10))\n",
    "plt.clim(-0.5, 9.5)\n",
    "plt.title(\"TSNE Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The TSNE algorithm is a dimension reduction algorithm that allows us to visualize high dimensional data in lower dimensions. We see that dataset form five clusters, which correlates with the five different tumor types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset into Train and Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# split data into training and testing set\n",
    "X_train, X_test, Y_train, Y_test \\\n",
    "    = train_test_split(X, Y, test_size=0.40, random_state=100)\n",
    "\n",
    "# save the train and test csv files\n",
    "X_train.to_csv(data_path+\"X_train.csv\")\n",
    "X_test.to_csv(data_path+\"X_test.csv\")\n",
    "Y_train.to_csv(data_path+\"Y_train.csv\")\n",
    "Y_test.to_csv(data_path+\"Y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In order for the dataset to feed into machine learning algorithms, every feature and label intended for machine learning should be numerical and scaled appropriately. In the previous step, we have transformed the labels into numerical values in preparing for t-SNE. The RNA expression features are already expressed in float numbers. Scaling is not necessary here because all feature data came from microarray measures. The only operation we need to perform is transforming panda data frame into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data\n",
    "X_train = pd.read_csv(data_path+\"X_train.csv\").values\n",
    "Y_train = pd.read_csv(data_path+\"Y_train.csv\").values\n",
    "\n",
    "X_test = pd.read_csv(data_path+\"X_test.csv\").values\n",
    "Y_test = pd.read_csv(data_path+\"Y_test.csv\").values\n",
    "\n",
    "# transform panda df into arrays\n",
    "X_train = np.delete(X_train, 0, axis=1)\n",
    "Y_train = np.delete(Y_train, 0, axis=1).flatten()\n",
    "\n",
    "X_test = np.delete(X_test, 0, axis=1)\n",
    "Y_test = np.delete(Y_test, 0, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models\n",
    "\n",
    "Considering the high dimensionalities nature of the problem, a basic linear classifier would have a hard time to come up with a clear boundary for classification. I chose four models that may be effective to work with high dimensional data. Then, I run grid search to find the optimal parameters for each model.\n",
    "\n",
    "###  Linear Support Vector Machine (SGD)\n",
    "\n",
    "It implements a linear support vector machine model using `hinge` loss function. It allows for minibatch learning, which means the model will continue to learn based on its learning rate, until the maximum iterations is reached or model stop improving\n",
    "- penalty: default is `l2`, which is not suitable for high dimensional data. `elasticnet` and `l1` may overcome this problem by introducing sparsity in the feature space\n",
    "- alpha: constant that multipilies the regularization term. Also determines learning rate when learning rate is set to optimal. Values tested are 0.0001, 0.5, 1, 5, 50, 100, 200, and 500\n",
    "- learning rate: can be constant, optimal or invscaling. Left at default optimal\n",
    "\n",
    "### Non-linear Support Vector Machine (SVC)\n",
    "\n",
    "Grid searched for three different non-linear kernel including `rbf`, `sigmoid`, and `poly`. Other parameters tuned including\n",
    "- C: error term. Values test are 1, 10, 100, 1000\n",
    "- gamma: kernel coefficient. Values tested are 0.001, 0.0001, and 0.00001\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "Random Forest is an algorithm that excels at finding complex hidden patterns in the data. It uses a collect of decision trees to fit, then use the average to improve predictive accuracy. The two parameters I set are n estimator and max leaf nodes. \n",
    "- n estimator: the maximum number of tree. Values tested are 10, 20, and 50\n",
    "- max leaf nodes: the maximum of leaf nodes. Values tested are 50, 100, 150 ,and 200\n",
    "\n",
    "### Neural Network MLP\n",
    "\n",
    "A multi-layer perceptron algorithm is used. It trains using backpropagation and supports multi-class classification by applying softmax as output function. It has the most options for parameter tuning\n",
    "- hidden layer size: the number of hidden layers. values tested are 50, 100, 150, and 200\n",
    "- alpha: L2 penalty (regularization term). Values tested are 0.0001, 0.0005, 0.001, and 0.005\n",
    "- activation: activation function for hidden layer. Options tested are `relu`, `tanh`, and `identity`\n",
    "- solver: the solver for weight optimization. `lbfgs` is optimal for smaller sample size. `Adam` is more suited for larger sample size. `sgd` refers to stochastic gradient descent\n",
    "- learning rate: sets the update schedule, `adaptive` keeps initial rate as long as training loss keep decreasing and decrease the rate when training loss goes up. Other two learning rate tested are `constant` and `invscaling`. For time efficiency, this parameter is left at default optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter tuning starts...\n",
      "Best params for sgd: {'alpha': 0.5, 'penalty': 'elasticnet'} \n",
      "\n",
      "Best params for svm: {'C': 1, 'gamma': 0.001, 'kernel': 'poly'} \n",
      "\n",
      "Best params for rf: {'max_leaf_nodes': 50, 'n_estimators': 50} \n",
      "\n",
      "Best params for nn: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': 200} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import svm, ensemble, linear_model\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the models\n",
    "sgd_clf = linear_model.SGDClassifier(random_state=100, n_jobs=-1, max_iter=5)\n",
    "svm_clf = svm.SVC(random_state=100)\n",
    "rf_clf = ensemble.RandomForestClassifier(random_state=100, n_jobs=-1)\n",
    "nn_clf = MLPClassifier(random_state=100)\n",
    "\n",
    "# paremeter tuning for sgd, by default sgd fits a linear svm\n",
    "print(\"Parameter tuning starts...\")\n",
    "parameters = {\n",
    "    'alpha': [0.0001, 0.5, 1, 5, 50, 100, 200, 500],\n",
    "    'penalty': ('l2', 'l1', 'elasticnet'),\n",
    "}\n",
    "sgd_clf = GridSearchCV(estimator=sgd_clf, param_grid=parameters).fit(X_train, Y_train)\n",
    "print(\"Best params for sgd:\", sgd_clf.best_params_, '\\n')\n",
    "\n",
    "# parameter tuning for non-linear svm kernel\n",
    "parameters = {\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'gamma': [0.001, 0.0001, 0.00001],\n",
    "    'kernel': ('poly', 'rbf', 'sigmoid')\n",
    "}\n",
    "svm_clf = GridSearchCV(estimator=svm_clf, param_grid=parameters).fit(X_train, Y_train)\n",
    "print(\"Best params for svm:\", svm_clf.best_params_, '\\n')\n",
    "\n",
    "# parameter tuning for random forest\n",
    "parameters = {\n",
    "    'n_estimators': [10, 20, 50],\n",
    "    'max_leaf_nodes': [50, 100, 150, 200]\n",
    "}\n",
    "rf_clf = GridSearchCV(estimator=rf_clf, param_grid=parameters).fit(X_train, Y_train)\n",
    "print(\"Best params for rf:\", rf_clf.best_params_, '\\n')\n",
    "\n",
    "# parameter tuning for neural network\n",
    "parameters = {\n",
    "    'hidden_layer_sizes': [50, 100, 150, 200],\n",
    "    'alpha': [0.0001, 0.0005, 0.001, 0.005],\n",
    "    'activation': ('relu', 'tanh', 'identity'),\n",
    "}\n",
    "nn_clf = GridSearchCV(estimator=nn_clf, param_grid=parameters).fit(X_train, Y_train)\n",
    "print(\"Best params for nn:\", nn_clf.best_params_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the optimal parameters has been tuning for each model. We can evaulate each model's performance by using cross validation on the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation \n",
    "K-fold cross validation is used to evaluate the performance of each model without touching the test dataset. Number of folds is set to 5. The dataset is partitioned into 5 sets, with 1 set being the testing data and rest 4 being the training data until all sets have taken turns. An alternative approach would be using leave one out, but it is much more computational intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM score: 0.989733\n",
      "\n",
      "Non-linear SVM score: 0.995876\n",
      "\n",
      "Random Forest score: 0.993814\n",
      "\n",
      "MPL Neural Network score: 0.983416\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cross validation to select the best model\n",
    "def kfold_model_score(model, X_train, Y_train, numFolds=5):\n",
    "    k_fold_shuttle = KFold(n_splits=numFolds, random_state=100).get_n_splits(X_train, Y_train)\n",
    "    return np.mean(cross_val_score(model, X_train, Y_train, cv=k_fold_shuttle))\n",
    "\n",
    "\n",
    "sgd_clf_score = kfold_model_score(sgd_clf, X_train, Y_train)\n",
    "print(\"Linear SVM score: {:5f}\\n\".format(sgd_clf_score.mean()))\n",
    "\n",
    "svm_score = kfold_model_score(svm_clf, X_train, Y_train)\n",
    "print(\"Non-linear SVM score: {:5f}\\n\".format(svm_score.mean()))\n",
    "\n",
    "rf_score = kfold_model_score(rf_clf, X_train, Y_train)\n",
    "print(\"Random Forest score: {:5f}\\n\".format(rf_score.mean()))\n",
    "\n",
    "nn_score = kfold_model_score(nn_clf, X_train, Y_train)\n",
    "print(\"MPL Neural Network score: {:5f}\\n\\n\".format(nn_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "With the information from cross validation, we see that linear-SVM, non-linear-SVM, and random forest all have very similar scores. We should train each model with training data, and then evaluate them with the testing data. The duration for training each model is measured to provided some ideas on the computational cost of each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd_clf training took 68.00 seconds\n",
      "\n",
      "SVM training took 667.85 seconds\n",
      "\n",
      "Random Forest training took 44.11 seconds\n",
      "\n",
      "Neural Network fitting took at 924.10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the models\n",
    "t0 = time.time()\n",
    "sgd_clf = sgd_clf.fit(X_train, Y_train)\n",
    "t1 = time.time()\n",
    "print(\"sgd_clf training took %.2f seconds\\n\" % (t1 - t0))\n",
    "\n",
    "t0 = time.time()\n",
    "svm_clf = svm_clf.fit(X_train, Y_train)\n",
    "t1 = time.time()\n",
    "print(\"SVM training took %.2f seconds\\n\" % (t1 - t0))\n",
    "\n",
    "t0 = time.time()\n",
    "rf_clf = rf_clf.fit(X_train, Y_train)\n",
    "t1 = time.time()\n",
    "print(\"Random Forest training took %.2f seconds\\n\" % (t1 - t0))\n",
    "\n",
    "t0 = time.time()\n",
    "nn_clf = nn_clf.fit(X_train, Y_train)\n",
    "t1 = time.time()\n",
    "print(\"Neural Network fitting took at %.2f seconds\\n\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation \n",
    "\n",
    "We can now use the models to predict the test data and evaluate their effectiveness. For multiclass problems, two score metrics used are Jaccard similarity coefficient and f1 score. Jaccard similarity coefficient measures the similarities between predicted classes and actual classes. A classification report is generated for each model to examine its precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity scores: \n",
      "SGD Jaccard similarity score: 1.000000\n",
      "\n",
      "SVM Jaccard similarity : 1.000000\n",
      "\n",
      "Random Forest Jaccard similarity score: 1.000000\n",
      "\n",
      "Neural Net Jaccard similarity score: 0.990654\n",
      "\n",
      "Classification report: \n",
      "SGD:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       112\n",
      "          1       1.00      1.00      1.00        27\n",
      "          2       1.00      1.00      1.00        58\n",
      "          3       1.00      1.00      1.00        62\n",
      "          4       1.00      1.00      1.00        62\n",
      "\n",
      "avg / total       1.00      1.00      1.00       321\n",
      " \n",
      "\n",
      "SVM:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       112\n",
      "          1       1.00      1.00      1.00        27\n",
      "          2       1.00      1.00      1.00        58\n",
      "          3       1.00      1.00      1.00        62\n",
      "          4       1.00      1.00      1.00        62\n",
      "\n",
      "avg / total       1.00      1.00      1.00       321\n",
      " \n",
      "\n",
      "RF:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       112\n",
      "          1       1.00      1.00      1.00        27\n",
      "          2       1.00      1.00      1.00        58\n",
      "          3       1.00      1.00      1.00        62\n",
      "          4       1.00      1.00      1.00        62\n",
      "\n",
      "avg / total       1.00      1.00      1.00       321\n",
      " \n",
      "\n",
      "NN:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       112\n",
      "          1       1.00      0.89      0.94        27\n",
      "          2       1.00      1.00      1.00        58\n",
      "          3       0.95      1.00      0.98        62\n",
      "          4       1.00      1.00      1.00        62\n",
      "\n",
      "avg / total       0.99      0.99      0.99       321\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'GridSearchCV' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-78939eb83514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'GridSearchCV' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.classification import classification_report, jaccard_similarity_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "sgd_pred = sgd_clf.predict(X_test)\n",
    "svm_pred = svm_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "nn_pred = nn_clf.predict(X_test)\n",
    "\n",
    "# measure and output accuracy\n",
    "print(\"Jaccard similarity scores: \")\n",
    "sgd_score = jaccard_similarity_score(Y_test, sgd_pred)\n",
    "svm_score = jaccard_similarity_score(Y_test, svm_pred)\n",
    "rf_score = jaccard_similarity_score(Y_test, rf_pred)\n",
    "nn_score = jaccard_similarity_score(Y_test, nn_pred)\n",
    "print(\"SGD Jaccard similarity score: {:5f}\\n\".format(sgd_score))\n",
    "print(\"SVM Jaccard similarity : {:5f}\\n\".format(svm_score))\n",
    "print(\"Random Forest Jaccard similarity score: {:5f}\\n\".format(rf_score))\n",
    "print(\"Neural Net Jaccard similarity score: {:5f}\\n\".format(nn_score))\n",
    "\n",
    "# measure and output f1 score\n",
    "print(\"Classification report: \")\n",
    "print(\"SGD:\") \n",
    "print(classification_report(Y_test, sgd_pred),\"\\n\")\n",
    "print(\"SVM:\") \n",
    "print(classification_report(Y_test, svm_pred),\"\\n\")\n",
    "print(\"RF:\") \n",
    "print(classification_report(Y_test, rf_pred),\"\\n\")\n",
    "print(\"NN:\") \n",
    "print(classification_report(Y_test, nn_pred))\n",
    "\n",
    "\n",
    "clf = OneVsRestClassifier(sgd_clf(random_state=100))\n",
    "y_score = clf.fit(X_test, Y_test).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(5):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(5):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "All four modeled performed well on the testing dataset. I am surprised by the result given such high dimensional feature spaces. SGD, SVM, and RF all achieved 100% in Jaccard similarity score. Neuron Network is slightly worse at 99% percent. I suspect this is due to parameter tuning which the optimal parameters were found for each algorithm. Another cause might be the features do not have much noise, so it's hard to for algorithms to perform badly. Considering the computational time, random forest and SGD are the most efficient algorithms in predicting the tumor outcomes given RNA microarray dataset. For future work, I would love to test the algorithms on more RNA microarray dataset or similar high dimensional problems. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
